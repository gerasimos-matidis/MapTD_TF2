{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6d575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools import parse_boxes_from_json, get_filenames\n",
    "from tiling import crop_ground_truths, get_random_tile\n",
    "from targets import generate as gen\n",
    "from visualize import render_boxes\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import cv2\n",
    "from pipeline_v2 import get_dataset, _get_filenames, _generate_tiles\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7973ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD/data/general_dataset/txt/D0117-5755036.txt'\n",
    "json_path = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD/data/general_dataset/json/D0117-5755036.json'\n",
    "img_path = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD/data/general_dataset/images/D0117-5755036.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276693dd-bab1-49ad-a9fd-d3b4aaf6b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD/data/general_dataset/images'\n",
    "json_dir = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD/data/general_dataset/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07cff9b-6f36-4350-a323-b3ad438e4924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Gerasimos\\Toponym_Recognition\\MapTD_General\\MapTD_TF2\\pipeline_v2.py:166: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From C:\\Users\\matge\\anaconda3\\envs\\deepenv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "ds = get_dataset(img_dir, json_dir, '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61368588-dabe-43ab-b6de-39e9a592c5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapAndBatchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edac2aee-abaf-46e0-851e-f94f72135064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.take(1)\n",
    "e = list(ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a3964-71c1-438c-acd6-8df192247ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.take(10)\n",
    "a = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcaf70b-828e-4554-9494-503a665478a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = lambda x : (x[0].astype(int), np.transpose(x[1], (2, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261283f-f841-4090-b902-c86010138c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_boxes(*args(list(next(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639d8f21-c4f7-4555-b10f-e531f6c8e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 128, 128, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6245d0-d2a0-4f3a-b4a1-0deaa14326bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7162e5-17f7-4a6b-aff2-edda8594a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, polygons, _ = parse_boxes_from_json(json_path)\n",
    "img = plt.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6fe3e-02ae-4bb4-9614-19fec9f62d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files, gt_files = _get_filenames(img_dir, json_dir, '*', 'tiff', 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0c84c-e83b-4413-bc97-194980d90559",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilegen = _generate_tiles(512, img_files, gt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b6c41-de0c-4833-a112-eec316f63088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(next(tilegen)[0])\n",
    "#plt.show()\n",
    "print(np.transpose(next(tilegen)[1], (2, 0, 1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428ffbf-bbd6-4963-b49d-f27df2a0c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, ground_truth = next(tilegen)\n",
    "render_boxes(image, np.transpose(ground_truth, (2, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e9a38-948e-417f-a484-8a17816bc6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "k = cv2.fillPoly(img, pts=np.transpose(points.astype(np.int32), (2, 0, 1)), color=(0, 0, 0)) # NOTE: check whether the points are in the shape (x, y, boxes) or (boxes, x, y)\n",
    "resized_img = cv2.resize(img, (1280, 720)) # NOTE: Resize image to fit in the screen. Otherwise, I must find how to enable the cv2.window_normal option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05011483",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('a name', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c31a2e-b589-499d-962f-91fc61ff3659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1d8acd67561793d0d4711492c21aa45930fc46ff826a8c13f35cfa9289d69f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
