{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41561d62-704b-4ec9-b2b7-439a01cfb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from maptd_model import maptd_model\n",
    "from IPython import display\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from tkinter.filedialog import askdirectory\n",
    "from pipeline_v2 import get_dataset, get_dataset_from_txt_files\n",
    "from losses import total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c260915e-5e89-4c25-ae15-c15388e6b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1563854-dc2c-46f0-ae61-eceef6837cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD_TF2/data/ckpts/models/0\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD_TF2/data/general_dataset/'\n",
    "INITIAL_DIR = 'D:/Gerasimos/Toponym_Recognition/MapTD_General/MapTD_TF2/data/ckpts/models'\n",
    "\n",
    "conf_file_dir = askdirectory(initialdir=INITIAL_DIR, title='Select the directory '\n",
    "    'with the configuration files')\n",
    "print(conf_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d2dfb0-4a63-4d99-9999-ca42481bc141",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[43mmaptd_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Gerasimos\\Toponym_Recognition\\MapTD_General\\MapTD_TF2\\maptd_model.py:38\u001b[0m, in \u001b[0;36mmaptd_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaptd_model\u001b[39m(input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 38\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     resnet_backbone \u001b[38;5;241m=\u001b[39m ResNet50(input_tensor\u001b[38;5;241m=\u001b[39minputs, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     40\u001b[0m     x \u001b[38;5;241m=\u001b[39m resnet_backbone\u001b[38;5;241m.\u001b[39mget_layer(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepenv\\lib\\site-packages\\keras\\engine\\input_layer.py:375\u001b[0m, in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly provide the `shape` OR `batch_input_shape` argument \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    372\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto Input, not both at the same time.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m type_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 375\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide to Input a `shape` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    376\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor a `tensor` or a `type_spec` argument. Note that \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    377\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`shape` does not include the batch \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    378\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "gen = maptd_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b58649-c3a9-4038-aae0-305aaaf49c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9106a4c-598d-451e-bfb1-fd9376f8c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[128, 128, 3], name='input_image')\n",
    "    tar_score = tf.keras.layers.Input(shape=[128, 128, 1], name='target_score_map')\n",
    "    tar_geo = tf.keras.layers.Input(shape=[128, 128, 5], name='target_geo_map')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar_score, tar_geo])  # (batch_size, 512, 512, 9)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)  # (batch_size, 256, 256, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256)\n",
    "    down4 = downsample(512, 4)(down3) # (batch_size, 32, 32, 512) #NOTE: Gerasimos changed the code here, it is not exactly the same as in pix2pix\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4)  # (batch_size, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar_score, tar_geo], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cfdf9-6b97-4c78-8be7-e1f00ea17f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb10f8c-4ac4-4f9a-b914-c4cd70d3058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009029ad-93b1-49f3-9488-747fd5012bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, score_map, gen_score_map, geo_map, \n",
    "                   gen_geo_map, training_mask):\n",
    "    \n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    loss = total_loss(score_map, gen_score_map, geo_map, gen_geo_map, training_mask)\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc3752-b1d3-4ebe-913a-53fbbc17526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdffd11-651c-41e3-8bfd-5718a9d4ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_score_map(tile, gt_score_map, pred_score_map, threshold=None):\n",
    "    pred_score_map = np.where(pred_score_map > threshold, 1, 0)\n",
    "    COLORMAP = 'gray'\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    ax[0].imshow(np.squeeze(tf.cast(tile, tf.uint8)))\n",
    "    ax[1].imshow(np.squeeze(gt_score_map), cmap=COLORMAP)\n",
    "    ax[2].imshow(np.squeeze(pred_score_map), cmap=COLORMAP)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9de2ba-a9a0-44ee-8b76-97256a03564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepDecayLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, initial_learning_rate, decay_rate, decay_every_n_steps):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_every_n_steps = decay_every_n_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        exp = tf.floor(step/self.decay_every_n_steps)\n",
    "        return self.initial_learning_rate * tf.pow(self.decay_rate, exp)\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_learning_rate, decay_rate, decay_on_step):\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_on_step = decay_on_step\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        new_lr = tf.cond(step < self.decay_on_step, \n",
    "                       lambda: self.initial_learning_rate,\n",
    "                       lambda: self.initial_learning_rate * self.decay_rate)\n",
    "        return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26ee34-f1d8-4a62-9647-47299402359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_to_reduce_lr=2**17\n",
    "initial_lr = 1e-4\n",
    "decay_rate = 0.1\n",
    "generator_optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=StepDecayLRSchedule(initial_lr, decay_rate, \n",
    "                                          step_to_reduce_lr), epsilon=1e-8)\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd3f3f-16f5-48e9-890b-6c945ee607fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(generator, discriminator, tile, \n",
    "               score_map, geo_map, training_mask, \n",
    "               step, summary_writer):\n",
    "    \n",
    "\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_score_map, gen_geo_map = generator(tile, training=True)\n",
    "        resized_input_image = tile[:, ::4, ::4, :]\n",
    "        disc_real_output = discriminator([resized_input_image, score_map, geo_map], training=True)\n",
    "        disc_generated_output = discriminator([resized_input_image, gen_score_map, gen_geo_map], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_loss = generator_loss(disc_generated_output, score_map, gen_score_map, geo_map, gen_geo_map, training_mask)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)\n",
    "        tf.summary.scalar('gen_loss', gen_loss, step=step//1000)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=step//1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14423611-f65e-4caa-b7b1-c352c9f02dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b442fbc-7259-46a3-b4af-24a19f9572da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(generator, discriminator, train_dataset, test_dataset, summary_writer,\n",
    "        total_steps=2**20, enumerate_from=0):\n",
    "    \n",
    "   \n",
    "    training_start = time.time()\n",
    "    start = training_start\n",
    "    for step, (tile, score_map, geo_map, training_mask) in \\\n",
    "                train_dataset.repeat().take(total_steps - enumerate_from).\\\n",
    "                enumerate(start=enumerate_from):\n",
    "        \n",
    "        train_step(generator, discriminator, tile,\n",
    "               score_map, geo_map, training_mask, \n",
    "               step, summary_writer)\n",
    "        \n",
    "        step = step.numpy()\n",
    "        \n",
    "        if (step + 1) % 500 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            print(datetime.datetime.now().strftime(\"%H:%M:%S\"))            \n",
    "            print(f'Step {step + 1}/{total_steps}')\n",
    "            \n",
    "            if step != 0 and step != enumerate_from:\n",
    "                print(f'Time taken for the last 500 steps: '\n",
    "                      f'{time.time()-start:.2f} sec')\n",
    "                estimated_remaining_time = int((time.time() - training_start) / \\\n",
    "                    (step - enumerate_from) * (total_steps - step))\n",
    "                print(f'Estimated time for the training to finish: '\n",
    "                      f'{estimated_remaining_time // 3600} hrs, '\n",
    "                      f'{int(estimated_remaining_time % 3600 / 60)} mins')\n",
    "            \n",
    "            print('Current Learning Rate: ', generator_optimizer.lr(step))\n",
    "                \n",
    "            \n",
    "            example_tile, example_score_map, _, _ = next(iter(test_dataset.take(1)))\n",
    "            example_pred_score_map, _ = generator(example_tile, training=True)\n",
    "            show_score_map(example_tile, \n",
    "                           example_score_map, \n",
    "                           example_pred_score_map, \n",
    "                           threshold=0.7)    \n",
    "            \n",
    "            start = time.time()\n",
    "               \n",
    "            \n",
    "        if (step + 1) % 10000 == 0:\n",
    "            ckpt.save(file_prefix=ckpt_prefix)\n",
    "            print(f'Checkpoint at step: {step + 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977dde8-a6f3-4266-8304-a5f9d0f7d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "\n",
    "# Define the m\n",
    "# Create log files\n",
    "log_dir = os.path.join(conf_file_dir, 'gan_logs')\n",
    "sum_writer = tf.summary.create_file_writer(os.path.join(log_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "\n",
    "# Initialize checkpoints\n",
    "ckpt_dir = os.path.join(conf_file_dir, 'gan_training_ckpts')\n",
    "ckpt_prefix = os.path.join(ckpt_dir, 'ckpt')\n",
    "ckpt = tf.train.Checkpoint(model=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f1ab9-3241-4077-aa41-b3fbd5e05314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset generators\n",
    "train_ds = get_dataset_from_txt_files(dataset_dir, conf_file_dir, 'train', batch_size=TRAIN_BATCH_SIZE)\n",
    "test_ds = get_dataset_from_txt_files(dataset_dir, conf_file_dir, 'test', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811dd45-1e7d-4b29-aa56-4752e9125358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(gen, disc, train_ds, test_ds, sum_writer, enumerate_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b80b0-10b5-47d2-b395-255a136f384d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
